Voici une version amÃ©liorÃ©e de votre README avec une meilleure structure, des formulations plus claires et des Ã©lÃ©ments visuels pour faciliter la comprÃ©hension. J'ai Ã©galement ajoutÃ© des badges pour les technologies utilisÃ©es et une section pour les contributeurs.

---

# **Lil-IA-ne** ğŸ“
*Un assistant d'orientation intelligent pour le **BTS SIO** du lycÃ©e Saint-Louis (ChÃ¢teaulin)*

[![Ollama](https://img.shields.io/badge/Ollama-3.2-ff69b4?logo=ollama)](https://ollama.com/)
[![Python](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python)](https://www.python.org/)
[![Node.js](https://img.shields.io/badge/Node.js-18%2B-green?logo=nodedotjs)](https://nodejs.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## **ğŸ“Œ PrÃ©sentation**
**Lil-IA-ne** est un **LLM (Large Language Model)** spÃ©cialisÃ© pour rÃ©pondre aux questions sur le **BTS SIO** (Options **SISR** et **SLAM**) du lycÃ©e Saint-Louis Ã  ChÃ¢teaulin.

### **Architecture**
Le projet se compose de deux parties principales :
1. **LLM** : Configuration du modÃ¨le de langage (rÃ©flexion, connaissances sur la formation).
2. **WebChat** : Interface web pour discuter avec l'assistant.

---

## **âš™ï¸ PrÃ©requis**
Avant de lancer le projet, assurez-vous d'avoir installÃ© :

| Outil | Lien | Version requise |
|--------|------|------------------|
| **Ollama** | [Site officiel](https://ollama.com/) | DerniÃ¨re version |
| **ModÃ¨le Llama 3.2** | [Ollama Library](https://ollama.com/library/llama3.2) | *(Modifiable)* |
| **Python 3.10+** | [TÃ©lÃ©chargement](https://www.python.org/downloads/) | + `pandas` (`pip install pandas`) |
| **Node.js 18+** | [TÃ©lÃ©chargement](https://nodejs.org/en) | + `express` (`npm i express`) |

---

## **ğŸ“‚ Structure du projet**
```
Lil-IA-ne/
â”œâ”€â”€ BTS_SIO_Infos.xlsx       # Base de connaissances (Ã  modifier)
â”œâ”€â”€ generate_data.py        # Script de compilation du LLM
â”œâ”€â”€ WebChat/
â”‚   â”œâ”€â”€ public/             # Fichiers statiques (images, CSS, JS)
â”‚   â”‚   â””â”€â”€ images/         # Dossier pour les images (locaux, schÃ©mas...)
â”‚   â”œâ”€â”€ config/             # Configuration du chat
â”‚   â”‚   â””â”€â”€ system-prompt.txt # Fichier gÃ©nÃ©rÃ© par generate_data.py
â”‚   â”œâ”€â”€ server.js           # Serveur Node.js
â”‚   â””â”€â”€ ...                 # Autres fichiers front/back
â””â”€â”€ README.md               # Ce fichier
```

---

## **ğŸ› ï¸ Configuration du LLM**
Les informations sur le BTS SIO sont stockÃ©es dans **`BTS_SIO_Infos.xlsx`**, organisÃ© en **onglets thÃ©matiques** :

| Onglet | Description |
|--------|-------------|
| **PrÃ©sentation GÃ©nÃ©rale** | Description globale du BTS SIO. |
| **Option SISR** | Contenu pÃ©dagogique de l'option **Solutions d'Infrastructure, SystÃ¨mes et RÃ©seaux**. |
| **Option SLAM** | Contenu pÃ©dagogique de l'option **Solutions Logicielles et Applications MÃ©tiers**. |
| **Admission** | CritÃ¨res et modalitÃ©s d'inscription. |
| **Stages** | Organisation et missions des pÃ©riodes de stage. |
| **DÃ©bouchÃ©s** | MÃ©tiers et poursuites d'Ã©tudes possibles. |
| **Equipements** | Locaux et matÃ©riel disponibles. |
| **Emploi du temps** | Exemple d'emploi du temps en 1Ã¨re annÃ©e. |
| **Vie Ã©tudiante** | Ã‰vÃ©nements organisÃ©s par le BDE. |
| **Contact** | CoordonnÃ©es (mails, rÃ©seaux, portes ouvertes...). |
| **Images** | Liste des images rÃ©fÃ©rencÃ©es (voir ci-dessous). |

### **Ajouter une image**
1. Placez votre image dans **`/WebChat/public/images/`**.
2. Remplissez l'onglet **"Images"** dans `BTS_SIO_Infos.xlsx` avec :
   - **Nom du fichier** (ex: `salle_info.jpg`)
   - **Description** (ex: *"Salle de TP rÃ©seaux Ã©quipÃ©e de routeurs Cisco"*).

âš ï¸ **Format supportÃ©** : `.jpg`, `.png`, `.svg` (optimisez la taille pour le web).

---

## **ğŸ”„ Compilation du LLM**
Pour appliquer vos modifications :
1. ExÃ©cutez le script de gÃ©nÃ©ration :
   ```bash
   python generate_data.py
   ```
2. Le fichier **`system-prompt.txt`** est gÃ©nÃ©rÃ© dans **`/WebChat/config/`**.

âœ… **Le modÃ¨le est prÃªt !**
*(Les Ã©tapes ci-dessus ne sont nÃ©cessaires que pour mettre Ã  jour les informations.)*

---

## **ğŸš€ Lancement du serveur**
1. **Ouvrez un terminal** et placez-vous dans `/WebChat`.
2. **Lancez Ollama** (dans un terminal sÃ©parÃ©) :
   ```bash
   ollama run llama3.2
   ```
3. **DÃ©marrez le serveur Node.js** :
   ```bash
   npm start
   ```
4. **AccÃ©dez Ã  l'interface** :
   ğŸ‘‰ [http://localhost:3000](http://localhost:3000)

---